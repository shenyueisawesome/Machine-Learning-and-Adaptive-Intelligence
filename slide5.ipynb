{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### week 5\n",
    "\n",
    "# Generalisation\n",
    "\n",
    "- over-fitting problem\n",
    "- hold out validation\n",
    "- leave one out and cross validation\n",
    "- bias variance tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pods\n",
    "import notebook as nb\n",
    "import mlai\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "basis = mlai.polynomial\n",
    "data = pods.datasets.olympic_marathon_men()\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "data_limits = [1892, 2020]\n",
    "num_data = x.shape[0]\n",
    "max_basis = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review and Preview\n",
    "\n",
    "- Last week we studied *basis functions*\n",
    "- We saw how the likelihood of a nonlinear regression model could be maximised\n",
    "- This week we look at an over-fitting problem in machine learning and explore how to validate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall: Olympic Marathon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x203a7ed1cf8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAFwCAYAAABU56uPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcbh533d6M5ugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203a7ed1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(data['X'], data['Y'], 'r.',markersize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alan Turing\n",
    "\n",
    "![Alan Turing running in 1946](http://www.turing.org.uk/turing/pi2/run.jpg)\n",
    "\n",
    "**Alan Turing** was a formidable Marathon runner.\n",
    "In 1946 he ran a time 2 hours 46 minutes, which was only 11 minutes slower than the winner of the 1948 games.\n",
    "\n",
    "Would he have won a hypothetical games held in 1946?\n",
    "What is the probability he won an Olympics if one had been held in 1946?\n",
    "\n",
    "Source: [Alan Turing Internet Scrapbook](http://www.turing.org.uk/scrapbook/run.html)\n",
    "\n",
    "Wikipedia: [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial Fits to Olymics Data\n",
    "\n",
    "Last week we saw an error function with basis functions (eg, polynomial basis):\n",
    "$$\n",
    "  E(\\mathbf{w},\\sigma^2) = \\frac{n}{2}\\log\\sigma^2 + \\sum_{i=1}^n \\frac{(y_i - \\mathbf{w}^\\top \\boldsymbol{\\phi}_i)^2}{2\\sigma^2}\n",
    "$$\n",
    "then used an algorithm to find values for $\\mathbf{w}$ and $\\sigma^2$ that minimised $E(\\mathbf{w},\\sigma^2)$ .\n",
    "\n",
    "Wikipedia: [Polynomial regression](https://en.wikipedia.org/wiki/Polynomial_regression)\n",
    "\n",
    "(next graph) finding polynomial fits when the number of basis are between 1 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./diagrams/olympic_LM_polynomial_num_basis004.svg'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.display_plots('olympic_LM_polynomial_num_basis{num_basis:0>3}.svg', directory='./diagrams', num_basis=(1, max_basis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We see that by using seven basis the polynomial fit better to the data than when using the less number of basis.\n",
    "\n",
    "Could we say - the more the basis the better the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting\n",
    "\n",
    "By increasing the number of basis functions we obtain a better 'fit' to the data.\n",
    "How will the model perform on previously unseen data?\n",
    "\n",
    "Wikipedia: [Overfitting](https://en.wikipedia.org/wiki/Overfitting)\n",
    "\n",
    "(next graph) suppose we know the winning time (red circles) up to year 1984, are we able to predict those (green) for the rest of years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./diagrams/olympic_val_LM_polynomial_num_basis004.svg'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.display_plots('olympic_val_LM_polynomial_num_basis{num_basis:0>3}.svg', directory='./diagrams', num_basis=(1, max_basis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extrapolation\n",
    "\n",
    "We are extrapolating beyond where the model has learnt.\n",
    "This is known as **extrapolation**.\n",
    "\n",
    "Here extrapolation is predicting into the future here but it could be:\n",
    "- predicting back to the unseen past (pre 1892)\n",
    "- spatial prediction (eg, Cholera rates outside Manchester given rates inside Manchester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpolation\n",
    "\n",
    "Predicting the wining time for 1946 Olympics is **interpolation**.\n",
    "There wasn't an Olympics between 1936 and 1948.\n",
    "\n",
    "If we want a model for interpolation how can we test it?\n",
    "One trick is to sample the validation set from throughout the dataset (eg, **hold out validation**)\n",
    "\n",
    "Wikipedia: [Regression validation](https://en.wikipedia.org/wiki/Regression_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hold Out Validation\n",
    "\n",
    "We assign data points to the **training set** and the **validation set**.\n",
    "\n",
    "Choice of the validation set should reflect how you will use the model in practice:\n",
    "- for **extrapolation** into the future we try validating with data from the future\n",
    "- for **interpolation** we choose the validation set from data\n",
    "\n",
    "For different validation sets we could get different results.\n",
    "\n",
    "(next graph) hold out validation: validation set is in green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./diagrams/olympic_val_inter_LM_polynomial_num_basis004.svg'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.display_plots('olympic_val_inter_LM_polynomial_num_basis{num_basis:0>3}.svg', directory='./diagrams', num_basis=(1, max_basis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave One Out Error\n",
    "\n",
    "1. remove one point from the dataset\n",
    "2. train a model from the remaining data\n",
    "3. compute the error on the removed point (which wasn't in the training data)\n",
    "4. repeat this for each point in the dataset in turn\n",
    "5. average the resulting error\n",
    "\n",
    "Wikipedia: [Leave-one-out error](https://en.wikipedia.org/wiki/Leave-one-out_error)\n",
    "\n",
    "(next graph) leave one out error: validation data is in green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./diagrams/olympic_loo013_LM_polynomial_num_basis004.svg'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb.display_plots('olympic_loo{part:0>3}_LM_polynomial_num_basis{num_basis:0>3}.svg', directory='./diagrams', num_basis=(1, max_basis), part=(0,x.shape[0]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias Variance Decomposition\n",
    "\n",
    "The expected error for a trained model $f^*$ with unseen data $(\\mathbf{x},y)$ is decomposed as\n",
    "$$\n",
    "  \\mathbb{E}\\left[ (y - f^*(\\mathbf{x}))^2 \\right] = \\left\\{ \\text{bias}\\left[ f^*(\\mathbf{x}) \\right] \\right\\}^2 + \\text{variance}\\left[ f^*(\\mathbf{x}) \\right] + \\sigma^2\n",
    "$$\n",
    "where\n",
    "\\begin{align*}\n",
    "  \\text{bias}\\left[ f^*(\\mathbf{x}) \\right] = & \\mathbb{E}\\left[ f^*(\\mathbf{x}) - f(\\mathbf{x}) \\right] \\\\\n",
    "  \\text{variance}\\left[ f^*(\\mathbf{x}) \\right] = & \\mathbb{E}\\left[ f^*(\\mathbf{x})^2 \\right] -  \\mathbb{E}\\left[ f^*(\\mathbf{x}) \\right]^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias Variance Tradeoff\n",
    "\n",
    "Bias:\n",
    "\n",
    "- error due to bias comes from a model that is too simple\n",
    "\n",
    "Variance:\n",
    "\n",
    "- slight variations of training set cause changes in the prediction\n",
    "- error due to variance is error in the model due to an overly complex model\n",
    "\n",
    "Wikipedia: [Bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-fold Cross Validation\n",
    "\n",
    "Leave one out error can be very time consuming because we need to repeat the algorithm $n$ times ($n$ is the number of data points).\n",
    "\n",
    "An alternative is $k$-fold cross validation.\n",
    "\n",
    "Wikipedia: [Cross validation](https://en.wikipedia.org/wiki/Cross-validation)\n",
    "\n",
    "(next graph) 5-fold cross validation: validation data is in green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_5cv00_BLM_polynomial_num_basis007.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
