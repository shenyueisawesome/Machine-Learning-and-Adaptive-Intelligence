{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### week 1\n",
    "\n",
    "# Probability and Other Preliminaries\n",
    "\n",
    "- probability distribution\n",
    "- rules of probability\n",
    "- review for linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pods\n",
    "import notebook as nb\n",
    "import mlai\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preview\n",
    "\n",
    "- topics this week mainly concerns a brief review for probability and linear algebra\n",
    "- lab class introduces use of Jupyter, Python and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability Distribution\n",
    "\n",
    "The **probability distribution function** of a random variable $X$ is\n",
    "$$\n",
    "  F(x) = P(X \\leq x)\n",
    "$$\n",
    "where the notation $\\{X \\leq x\\}$ consists of all outcomes smaller than or equal to $x$.\n",
    "\n",
    "The derivative\n",
    "$$\n",
    "  p(x) = \\frac{dF(x)}{dx}\n",
    "$$\n",
    "is called the **probability density function** of $X$ .\n",
    "\n",
    "Wikipedia:\n",
    "[Probability distribution](https://en.wikipedia.org/wiki/Probability_distribution) /\n",
    "[Probability density function](https://en.wikipedia.org/wiki/Probability_density_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Joint Distribution\n",
    "\n",
    "The **joint distribution function** of two random variables $X$ and $Y$ is the probability of the joint statistics $\\{X \\leq x, Y \\leq y\\}$, ie,\n",
    "$$\n",
    "  F(x, y) = P(X \\leq x, Y \\leq y)\n",
    "$$\n",
    "\n",
    "The derivative\n",
    "$$\n",
    "  p(x, y) = \\frac{\\partial^2 F(x, y)}{\\partial x \\partial y}\n",
    "$$\n",
    "is called the **joint density function** of $X$ and $Y$ .\n",
    "\n",
    "- $X$ and $Y$ are **independent** if and only if $p(x,y) = p(x)p(y)$\n",
    "\n",
    "Wikipedia: [Joint probability distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Distribution\n",
    "\n",
    "Given two jointly distributed random variables $X$ and $Y$, the **conditional probability distribution** of $Y$ given $X$ is the probability distribution of $Y$ when $X$ is known to be a particular value.\n",
    "\n",
    "The **conditional density function** of $y$ given the occurrence of the value $x$ is\n",
    "$$\n",
    "  p(y|x) = \\frac{p(x,y)}{p(x)}\n",
    "$$\n",
    "\n",
    "Wikipedia: [Conditional probability distribution](https://en.wikipedia.org/wiki/Conditional_probability_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian (Normal) Distribution\n",
    "\n",
    "The probability density of the **Gaussian distribution** is\n",
    "$$\n",
    "  p(x\\ |\\ \\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "where $\\mu$ is the **mean** and $\\sigma^2$ is the **variance** of the distribution.\n",
    "\n",
    "- very common in natural and social sciences\n",
    "- $\\sigma$ is the **standard deviation**\n",
    "\n",
    "Wikipedia: [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Normal (Gaussian) Distribution\n",
    "\n",
    "<div align=\"right\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Gaussian_distribution.svg/640px-Gaussian_distribution.svg.png\", width=700>\n",
    "</div>\n",
    "\n",
    "- about 68% of values drawn from a Gaussian distribution are within one standard deviation $\\sigma$ from the mean $\\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multivariate Gaussian (Normal) Distribution\n",
    "\n",
    "The probability density of the $k$-dimensional **Gaussian distribution** is\n",
    "$$\n",
    "  p(\\mathbf{x}\\ |\\ \\boldsymbol{\\mu},\\boldsymbol{\\Sigma}) = \\frac{1}{\\sqrt{2\\pi^k |\\boldsymbol{\\Sigma}|}} \\exp\\left( -\\frac{1}{2} (\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x}-\\boldsymbol{\\mu}) \\right)\n",
    "$$\n",
    "where $\\boldsymbol{\\mu}$ is the $k\\times 1$ **mean vector** and $\\boldsymbol{\\Sigma}$ is the $k\\times k$ **covariance matrix**.\n",
    "\n",
    "- $|\\boldsymbol{\\Sigma}|$ and $\\boldsymbol{\\Sigma}^{-1}$ are the **determinant** and the **inverse** of the covariance\n",
    "- a symbol $~^\\top$ indicates the **transpose**\n",
    "\n",
    "Wikipedia: [Multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Notation\n",
    "\n",
    "Formally we should write out $p(X=x,Y=y)$ .\n",
    "\n",
    "In practice we often use $p(x,y)$ .\n",
    "\n",
    "- this looks very much like we might write a multivariate function, eg, $f(x,y) = \\frac{x}{y}$\n",
    "- for a multivariate function though, $f(x,y)\\neq f(y,x)$\n",
    "- however $p(x,y) = p(y,x)$ because $p(X=x,Y=y) = p(Y=y,X=x)$\n",
    "\n",
    "We now quickly review the **rules of probability**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalisation\n",
    "\n",
    "All distributions are normalised.\n",
    "\n",
    "- this is clear from the fact that $\\sum_{x\\in {\\cal X}} n_{x} = N$, which gives\n",
    "$$\n",
    "  \\sum_{x\\in {\\cal X}} p(x) = \\lim_{N\\rightarrow\\infty} \\frac{\\sum_{x\\in {\\cal X}} n_x}{N} = \\lim_{N\\rightarrow\\infty} \\frac{N}{N} = 1\n",
    "$$\n",
    "\n",
    "A similar result can be derived for the marginal and conditional distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Product Rule and Sum Rule\n",
    "\n",
    "The product rule of probability:\n",
    "$$\n",
    "  \\underbrace{p(x,y)}_{\\text{joint probability}} = \\underbrace{p(y|x)}_{\\text{conditional probability}}\\cdot\\ p(x)\n",
    "$$\n",
    "\n",
    "The sum rule of probability:\n",
    "$$\n",
    "  \\underbrace{p(y)}_{\\text{marginal probability}} = \\sum_{x\\in {\\cal X}} p(x,y) = \\sum_{x\\in {\\cal X}} p(y|x)p(x)\n",
    "$$\n",
    "\n",
    "Wikipedia:\n",
    "[Product rule](https://en.wikipedia.org/wiki/Product_rule) /\n",
    "[Probability axioms](https://en.wikipedia.org/wiki/Probability_axioms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes' Theorem\n",
    "\n",
    "Bayes' theorem immediately follows the product rule:\n",
    "$$\n",
    "  p(x|y) = \\frac{p(x,y)}{p(y)} = \\frac{p(y|x)p(x)}{\\displaystyle \\sum_{x\\in {\\cal X}} p(y|x)p(x)}\n",
    "$$\n",
    "\n",
    "Wikipedia: [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)\n",
    "\n",
    "(**Example**)\n",
    "There are two barrels in front of you.\n",
    "Barrel One contains 20 apples and 4 oranges.\n",
    "Barrel One contains 4 apples and 8 oranges.\n",
    "You choose a barrel randomly and select a fruit.\n",
    "It is an **apple**.\n",
    "What is the probability that the barrel was Barrel One?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(**Solution**) we are given that:\n",
    "\\begin{align*}\n",
    "  p(\\text{apple}\\ |\\ \\text{B}_1) = & \\frac{20}{24} & \\qquad p(\\text{B}_1) = 0.5 \\\\\n",
    "  p(\\text{apple}\\ |\\ \\text{B}_2) = & \\frac{4}{12} & \\qquad p(\\text{B}_2) = 0.5\n",
    "\\end{align*}\n",
    "Use the sum rule to calculate\n",
    "$$\n",
    "  p(\\text{apple}) = p(\\text{apple}\\ |\\ \\text{B}_1)p(\\text{B}_1) + p(\\text{apple}\\ |\\ \\text{B}_2)P(\\text{B}_2) = \\frac{20}{24}\\times 0.5 + \\frac{4}{12}\\times 0.5 = \\frac{7}{12}\n",
    "$$\n",
    "and Bayes' theorem tells us that:\n",
    "$$\n",
    "  p(\\text{B}_1\\ |\\ \\text{apple}) = \\frac{p(\\text{apple}\\ |\\ \\text{B}_1)P(\\text{B}_1)}{P(\\text{apple})} = \\frac{\\frac{20}{24}\\times 0.5}{\\frac{7}{12}} = \\frac{5}{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expected Value\n",
    "\n",
    "The **expected value** (or mean, average) of a random variable $X$ is\n",
    "$$\n",
    "  \\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} xp(x) dx\n",
    "$$\n",
    "\n",
    "- discrete type is $\\mathbb{E}[X] = \\sum_{x\\in {\\cal X}} x p(x)$ for all possible events ${\\cal X}$\n",
    "\n",
    "The expected value of a function $f(x)$ is\n",
    "$$\n",
    "  \\mathbb{E}[f(x)] = \\int_{-\\infty}^{\\infty} f(x) p(x) dx\n",
    "$$\n",
    "\n",
    "Wikipedia: [Expected value](https://en.wikipedia.org/wiki/Expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variance\n",
    "\n",
    "The **variance** is the expected value of $f(x) = (x - \\mathbb{E}[X])^2$, ie,\n",
    "$$\n",
    "  \\mathbb{V}ar[X] = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\int_{-\\infty}^{\\infty} (x - \\mathbb{E}[X])^2 p(x) dx\n",
    "$$\n",
    "\n",
    "- discrete type is $\\mathbb{V}ar[X] = \\sum_{x\\in {\\cal X}} (x - \\mathbb{E}[X])^2 p(x)$\n",
    "\n",
    "(note)\n",
    "$\n",
    "  \\mathbb{V}ar[X]\n",
    "  = \\mathbb{E}[(X - \\mathbb{E}[X])^2]\n",
    "  = \\mathbb{E}[X^2 - 2X\\mathbb{E}(X) + \\mathbb{E}[X]^2]\n",
    "  = \\mathbb{E}[X^2] - 2\\mathbb{E}(X)\\mathbb{E}(X) + \\mathbb{E}[X]^2\n",
    "  = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "$\n",
    "\n",
    "Wikipedia: [Variance](https://en.wikipedia.org/wiki/Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Derivatives with Vectors\n",
    "\n",
    "We have scalars $x$, $y$, and $n$- and $m$-dimensional vectors $\\mathbf{x}$, $\\mathbf{y}$, where\n",
    "$$\n",
    "  \\mathbf{x} = \\left( \\begin{array}{c} x_1 \\\\ \\vdots \\\\ x_n \\end{array} \\right)\n",
    "  \\qquad\n",
    "  \\mathbf{y} = \\left( \\begin{array}{c} y_1 \\\\ \\vdots \\\\ y_m \\end{array} \\right)\n",
    "$$\n",
    "Derivatives with vectors using the **denominator-layout** notation:\n",
    "$$\n",
    "  \\frac{\\partial \\mathbf{y}}{\\partial x} = \\left( \\frac{\\partial y_1}{\\partial x} \\cdots \\frac{\\partial y_m}{\\partial x} \\right)\n",
    "  \\qquad\n",
    "  \\frac{\\partial y}{\\partial \\mathbf{x}} = \\left( \\begin{array}{c} \\frac{\\partial y}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial y}{\\partial x_n} \\end{array} \\right)\n",
    "  \\qquad\n",
    "  \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\left( \\begin{array}{ccc} \\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_1} \\\\ \\vdots & & \\vdots \\\\ \\frac{\\partial y_1}{\\partial x_n} & \\cdots & \\frac{\\partial y_m}{\\partial x_n} \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some Scalar-by-Vector Identities\n",
    "\n",
    "For vectors $\\mathbf{a}$, $\\mathbf{w}$ and a square matrix $\\mathbf{A}$ :\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial \\mathbf{a}^\\top \\mathbf{w}}{\\partial \\mathbf{w}} = & \\mathbf{a} \\\\\n",
    "  \\frac{\\partial \\mathbf{w}^\\top \\mathbf{A} \\mathbf{w}}{\\partial \\mathbf{w}} = & (\\mathbf{A} + \\mathbf{A}^\\top)\\mathbf{w}\n",
    "\\end{align*}\n",
    "\n",
    "Wikipedia: [Matrix calculus](https://en.wikipedia.org/wiki/Matrix_calculus)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
